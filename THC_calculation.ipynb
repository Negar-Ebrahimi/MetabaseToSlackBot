{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HostConcludingUserType HostConclusionType Percentage  THC_median\n",
      "0                 Jabama            Decline      5.00%        23.0\n",
      "1                   User            Payment     95.00%         3.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import env\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "class Data:\n",
    "    METABASE_SESSION = \"\"\n",
    "\n",
    "def getMetaCards(card_ids):\n",
    "    responses = []\n",
    "    for card_id in card_ids:\n",
    "        url = \"http://metabase.jabama.com/api/card/\" + str(card_id) + \"/query\"\n",
    "\n",
    "        headers = {\n",
    "            'Content-Type': \"application/json\",\n",
    "            'X-Metabase-Session': Data.METABASE_SESSION,\n",
    "            }\n",
    "\n",
    "        responses.append([card_id, requests.request(\"POST\", url, headers=headers)])\n",
    "    return responses\n",
    "\n",
    "def getDataFromPivotResponses(responses):\n",
    "    responses_data = []\n",
    "    \n",
    "    for response in responses:\n",
    "        cols = json.loads(response[1].text)['data']['cols']\n",
    "        rows = json.loads(response[1].text)['data']['rows']\n",
    "        card_id = response[0]\n",
    "        col_titles = []\n",
    "        for col in cols:\n",
    "            col_titles.append(col['name'])\n",
    "\n",
    "        responses_data.append({\n",
    "            \"card_id\": card_id,\n",
    "            \"columns\": col_titles,\n",
    "            \"rows\": rows\n",
    "        })\n",
    "    return responses_data\n",
    "\n",
    "def transformPivotResponseToDataFrame(pivotResponse):\n",
    "    job_audit_df = pd.DataFrame(\n",
    "        pivotResponse.get(\"rows\"),\n",
    "        columns = pivotResponse.get(\"columns\")\n",
    "    )[\n",
    "        [\n",
    "            \"id\",\n",
    "            \"OrderId\",\n",
    "            \"PlaceCategory\",\n",
    "            \"WorkflowStepId\",\n",
    "            \"previous_workflowstepid\",\n",
    "            \"next_workflowstepid\",\n",
    "            \"nth\",\n",
    "            \"CreatedDate\",\n",
    "            \"UpdatedDate\",\n",
    "            \"UpdatedBy\"\n",
    "        ]\n",
    "    ]\n",
    "    return job_audit_df\n",
    "\n",
    "def extractPrebookOrders(job_audit_df):\n",
    "    prebook_orders_list = []\n",
    "    prebook_flag = 0\n",
    "    for indx, job_audit in job_audit_df.iterrows():\n",
    "        \n",
    "        if job_audit_df[\"nth\"].iloc[indx] == 1:\n",
    "            if prebook_flag == 1:\n",
    "                prebook_flag = 0\n",
    "                prebook_orders_list.append(prebook_list)\n",
    "            if job_audit_df[\"WorkflowStepId\"].iloc[indx] == \"init\" \\\n",
    "            and job_audit_df[\"next_workflowstepid\"].iloc[indx] == \"init\":\n",
    "                prebook_flag = 1\n",
    "                prebook_list = []\n",
    "        if prebook_flag == 1:\n",
    "            prebook_list.append(job_audit)\n",
    "    return prebook_orders_list\n",
    "    \n",
    "def extractInstantOrders(job_audit_df):\n",
    "    instant_orders_list = []\n",
    "    instant_flag = 0\n",
    "    for indx, job_audit in job_audit_df.iterrows():     \n",
    "        if job_audit_df[\"nth\"].iloc[indx] == 1:\n",
    "            if instant_flag == 1:\n",
    "                instant_flag = 0\n",
    "                instant_orders_list.append(instant_list)\n",
    "            if job_audit_df[\"WorkflowStepId\"].iloc[indx] == \"init\" \\\n",
    "            and job_audit_df[\"next_workflowstepid\"].iloc[indx] != \"init\":\n",
    "                instant_flag = 1\n",
    "                instant_list = []\n",
    "        if instant_flag == 1:\n",
    "            instant_list.append(job_audit)\n",
    "    return instant_orders_list\n",
    "    \n",
    "def splitOrderPathToSubPaths(prebook_batches):\n",
    "    prebook_splitted_batches = []\n",
    "    for prebook_batch in prebook_batches:\n",
    "            being_splitted_list = []\n",
    "            counting_off_flag = 0\n",
    "            for job_audit in prebook_batch:\n",
    "                if counting_off_flag == 0:\n",
    "                    being_splitted_list.append(job_audit)\n",
    "                if job_audit[\"WorkflowStepId\"] == \"payment\" \\\n",
    "                or job_audit[\"WorkflowStepId\"] == \"supplydecline\":\n",
    "                    counting_off_flag = 1\n",
    "                if (job_audit[\"WorkflowStepId\"] == \"paymenttimeout\" \\\n",
    "                    and job_audit[\"next_workflowstepid\"] == \"init\"):\n",
    "                    prebook_splitted_batches.append(being_splitted_list)\n",
    "                    being_splitted_list = []\n",
    "                    counting_off_flag = 0\n",
    "            prebook_splitted_batches.append(being_splitted_list)\n",
    "                \n",
    "    return prebook_splitted_batches\n",
    "\n",
    "def inferTheStepUserTypeFromJobAudit(job_audit):\n",
    "    StepUserType = \"Jabama\"\n",
    "    if not (job_audit[\"WorkflowStepId\"] == \"payment\" \\\n",
    "    or job_audit[\"WorkflowStepId\"] == \"supplydecline\"):\n",
    "        return StepUserType\n",
    "    if job_audit[\"UpdatedBy\"] == \"\" \\\n",
    "    or ((\"jabama\" in job_audit[\"UpdatedBy\"] \\\n",
    "    or \"Jabama\" in job_audit[\"UpdatedBy\"] \\\n",
    "    or job_audit[\"UpdatedBy\"][0] == \"0\" \\\n",
    "    or job_audit[\"UpdatedBy\"][0] == \"+\") \\\n",
    "    and not(job_audit[\"UpdatedBy\"][-10:] == \"alibaba.ir\" \\\n",
    "            or job_audit[\"UpdatedBy\"][-10:] == \"Alibaba.ir\")):\n",
    "        StepUserType = \"User\"\n",
    "    return StepUserType\n",
    "  \n",
    "def calculateTimeToHostConclusion_df(prebook_splitted_batches):\n",
    "    host_conclusion_prebook_splitted_batches = pd.DataFrame(dtype=float, columns = [\"sub_order\", \"THC\", \"HostConcludingUserType\", \"HostConclusionType\"])\n",
    "    for prebook_splitted_batch in prebook_splitted_batches:\n",
    "        start_dt = prebook_splitted_batch[0][\"CreatedDate\"]\n",
    "        if start_dt[22] == \"+\":\n",
    "            start_dt = start_dt[:22] + '0' + start_dt[22:]\n",
    "        if start_dt[21] == \"+\":\n",
    "            start_dt = start_dt[:21] + '00' + start_dt[21:]\n",
    "        if start_dt[19] == \"+\":\n",
    "            start_dt = start_dt[:19] + '.000' + start_dt[19:]\n",
    "            \n",
    "        end_dt = prebook_splitted_batch[-1][\"UpdatedDate\"]\n",
    "        if end_dt[22] == \"+\":\n",
    "            end_dt = end_dt[:22] + '0' + end_dt[22:]\n",
    "        if end_dt[21] == \"+\":\n",
    "            end_dt = end_dt[:21] + '00' + end_dt[21:]\n",
    "        if end_dt[19] == \"+\":\n",
    "            end_dt = end_dt[:19] + '.000' + end_dt[19:]\n",
    "  \n",
    "        THC = datetime.fromisoformat(end_dt) - datetime.fromisoformat(start_dt)\n",
    "        ConcludingUserType = inferTheStepUserTypeFromJobAudit(prebook_splitted_batch[-1])\n",
    "        \n",
    "        ConclusionType = \"Decline\"\n",
    "        if prebook_splitted_batch[-1][\"WorkflowStepId\"] == \"payment\":\n",
    "            ConclusionType = \"Payment\"\n",
    "            \n",
    "        host_conclusion_prebook_splitted_batches = host_conclusion_prebook_splitted_batches.append({\n",
    "         \"sub_order\": prebook_splitted_batch,\n",
    "         \"THC\": (THC.seconds//60)%60,\n",
    "         \"HostConcludingUserType\": ConcludingUserType,\n",
    "         \"HostConclusionType\": ConclusionType\n",
    "        }, ignore_index=True)\n",
    "    return host_conclusion_prebook_splitted_batches\n",
    "\n",
    "def host_conclusion_job():\n",
    "    #Get and store the raw data of union of questions from Metabase.\n",
    "    pivot_metacard_responses = getMetaCards([env.CARD_ID_JOBAUDIT])\n",
    "    pivot_responses_data = getDataFromPivotResponses(pivot_metacard_responses)\n",
    "    job_audit_df = transformPivotResponseToDataFrame(pivot_responses_data[0])\n",
    "    \n",
    "    prebook_order_batches_list = extractPrebookOrders(job_audit_df)\n",
    "    instant_order_batches_list = extractInstantOrders(job_audit_df)\n",
    "\n",
    "    prebook_splitted_batches = splitOrderPathToSubPaths(prebook_order_batches_list)\n",
    "    prebook_splitted_batches_with_THC = calculateTimeToHostConclusion_df(prebook_splitted_batches)\n",
    "\n",
    "    #THC_result_df = prebook_splitted_batches_with_THC.groupby([\"HostConcludingUserType\", \"HostConclusionType\"], as_index = False).median()\n",
    "    total_prebook_splitted_batches = len(prebook_splitted_batches_with_THC)\n",
    "    THC_aggregated_df = prebook_splitted_batches_with_THC.groupby([\"HostConcludingUserType\", \"HostConclusionType\"], as_index = False).agg([np.median, 'count'])\n",
    "    THC_aggregated_df.columns = THC_aggregated_df.columns.droplevel(0)\n",
    "    THC_aggregated_df = THC_aggregated_df.reset_index()[[\"HostConcludingUserType\", \"HostConclusionType\", \"median\", \"count\"]]\n",
    "    THC_aggregated_df = THC_aggregated_df.rename(columns={\"median\": \"THC_median\", \"count\": \"SubOrders_Count\"})\n",
    "    THC_aggregated_df[\"Percentage\"] = THC_aggregated_df[\"SubOrders_Count\"] / total_prebook_splitted_batches * 100\n",
    "    THC_aggregated_df[\"Percentage\"] = THC_aggregated_df[\"Percentage\"].map(\"{:,.2f}%\".format)\n",
    "    \n",
    "    THC_result_df = THC_aggregated_df[[\"HostConcludingUserType\", \"HostConclusionType\", \"Percentage\", \"THC_median\"]]\n",
    "    return THC_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
